<html>

<head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
    <title>Agents lab</title>
    <meta name="description" content="Agents lab">


    <title>Agents lab</title>
</head>

<body>
    <div id="maincontent">
        <ul class="navlist">
            <li class="active"><a href="./index.html">About</a></li>
            <li><a href="./vision.html">Vision</a></li>
            <li><a href="./join_us.html">Join Us</a></li>
            <li><a href="./contact.html">Contact</a></li>
            <!-- <li style="float:right"><img src="images/logo-64.gif" alt="tess" width="30px"><a href="./index.html"></a></li> -->
        </ul>


        <h1>Teachable agents</h1>
        GPT compresses all available knowledge on the internet into a model. Agents based on gpt use this information to accomplish tasks. 

Agents can do what gpt knows, but cannot be taught new things. E.g. an agent can play chess against you and defeat you, because gpt knows a lot about chess. But an agent cannot create a website, because gpt:
 
Everyone builds websites differently. Some use figma for design others use drawio. LLM information is general and it doesn't know how you would want to build it. 
Cannot act. It doesnâ€™t have access to websites or tools needed to design, build or deploy websites. 

But website making can be learnt. We learn by working with other people who make websites, we generalize what we see, ask questions when we have doubts, and test our learning to see if it works. We want to build an agent that can be taught things similarily.  

It is argued that we can also write all steps of a task well and get an agents to do them. Such an explicit description of tasks is impossible in human language. It is like trying to teach someone how to cycle by giving written instructions. It is easier to teach by showing. It is easier to learn by copying and trying. 

        
    </div>



</body>

</html>
